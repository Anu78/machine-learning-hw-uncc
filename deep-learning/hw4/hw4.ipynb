{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49dc435d-260e-4c29-86fb-ea0909be5532",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import regex as re\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a05beff6-9bbb-4b69-9a5d-f3a3386bfeae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dataset using pd\n",
    "dtypes = {\n",
    "  'en': 'str',\n",
    "  'fr': 'str'\n",
    "}\n",
    "df = pd.read_csv(\"small_en-fr.csv\", dtype=dtypes) \n",
    "all_text = \"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5b069958",
   "metadata": {},
   "outputs": [],
   "source": [
    "for en, fr in zip(df[\"en\"][:1000], df[\"fr\"][:1000]):\n",
    "  all_text += str(en) + \" \" + str(fr) + \" \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6772edee",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded = list(map(int, all_text.encode(\"utf-8\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3429e0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer: build a list of tokens in each language. BPE utilized here. \n",
    "def get_stats(ids):\n",
    "  counts = {}\n",
    "  for pair in zip(ids, ids[1:]):\n",
    "    counts[pair] = counts.get(pair, 0) + 1\n",
    "  return counts\n",
    "\n",
    "def merge(ids, pair, idx):\n",
    "  newids = []\n",
    "  i = 0\n",
    "  while i < len(ids):\n",
    "    if i < len(ids) - 1 and ids[i] == pair[0] and ids[i+1] == pair[1]:\n",
    "      newids.append(idx)\n",
    "      i += 2\n",
    "    else:\n",
    "      newids.append(ids[i])\n",
    "      i += 1\n",
    "  return newids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c7c35332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bpe hyperparameters: \n",
    "num_merges = 100 \n",
    "replacements = {}  # order of merges matters\n",
    "for i in range(num_merges):\n",
    "  stats = get_stats(encoded)\n",
    "  best = max(stats, key=stats.get)\n",
    "  encoded = merge(encoded, best, 256 + i)\n",
    "  replacements[best] = 256 + i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "91af3145",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(text):\n",
    "  ids = list(map(int, text.encode(\"utf-8\")))\n",
    "  for pair in list(replacements):\n",
    "    merged = merge(ids, pair, replacements[pair])\n",
    "    ids = merged\n",
    "  return ids\n",
    "def decode(ids):\n",
    "    decoded_ids = ids[:]\n",
    "    for merge_id in range(256 + num_merges - 1, 255, -1):  # Go backwards through merge ids\n",
    "        original_pair = None\n",
    "        for pair, replacement in replacements.items():\n",
    "            if replacement == merge_id:\n",
    "                original_pair = pair\n",
    "                break\n",
    "        if original_pair is not None:\n",
    "            i = 0\n",
    "            while i < len(decoded_ids):\n",
    "                if decoded_ids[i] == merge_id:\n",
    "                    decoded_ids = decoded_ids[:i] + list(original_pair) + decoded_ids[i+1:]\n",
    "                i += 1\n",
    "\n",
    "    byte_array = bytearray(decoded_ids)\n",
    "    return byte_array.decode(\"utf-8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9f98283f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, hidden_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        self.gru = nn.GRU(emb_dim, hidden_dim)\n",
    "\n",
    "    def forward(self, src):\n",
    "        embedded = self.embedding(src)  # embedded: [src len, batch size, emb dim]\n",
    "        outputs, hidden = self.gru(embedded)  # hidden: [1, batch size, hidden dim]\n",
    "        return hidden\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "659a8cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoder\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, hidden_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "        self.gru = nn.GRU(emb_dim, hidden_dim)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        # input: [batch size]\n",
    "        # hidden: [1, batch size, hidden dim]\n",
    "        input = input.unsqueeze(0)  # input: [1, batch size]\n",
    "        embedded = self.embedding(input)  # embedded: [1, batch size, emb dim]\n",
    "        output, hidden = self.gru(embedded, hidden)\n",
    "        prediction = self.fc(output.squeeze(0))  # prediction: [batch size, output dim]\n",
    "        return prediction, hidden\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cfba8142",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined model from encoder and decoder\n",
    "class Translator(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super(Translator, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n",
    "        # src: [src len, batch size]\n",
    "        # trg: [trg len, batch size]\n",
    "        trg_len = trg.shape[0]\n",
    "        batch_size = trg.shape[1]\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "        \n",
    "        # tensor to store decoder outputs\n",
    "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
    "        \n",
    "        # last hidden state of the encoder is used as the initial hidden state of the decoder\n",
    "        hidden = self.encoder(src)\n",
    "        \n",
    "        # first input to the decoder is the <sos> tokens\n",
    "        input = trg[0,:]\n",
    "        \n",
    "        for t in range(1, trg_len):\n",
    "            output, hidden = self.decoder(input, hidden)\n",
    "            outputs[t] = output\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            top1 = output.argmax(1) \n",
    "            input = trg[t] if teacher_force else top1\n",
    "        \n",
    "        return outputs\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
